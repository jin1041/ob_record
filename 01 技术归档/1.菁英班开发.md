# python用法记录

```python
import argparse
import yolov
import os
import  subprocess
import random
import time
import json
import pandas as pd
import numpy as np
import shutil

def prepare_output():
    '''
    :param args: NONE
    :return: NONE
    功能1(实践1):该函数检查训练输出目录下的weights文件夹并将新产生的checkpoint拷贝至算子model输出目录
    功能2(实践2):该函数检查训练输出目录下的result.csv文件并将新产生训练日志进行解析按规定格式放入至算子report输出目录
    '''

    # 1.复制到model输出目录

    # 创建存储结果的文件夹 /root/data/output/report  /root/data/output/report
    # 输出文件夹 /root/data/output
    temp_output_folder = os.path.join("data", "output_temp")
    os.makedirs(temp_output_folder, exist_ok= True)
    output_report_folder = os.path.join( "data", "output", train_args.output.split(",")[0])
    output_model_folder = os.path.join("data", "output", train_args.output.split(",")[1])
    os.makedirs(output_model_folder, exist_ok = True)
    os.makedirs(output_report_folder, exist_ok = True)
    pretrain_dir = train_args.input.split(",")[1]
    for i in os.listdir('/root/data/input/{}/'.format(pretrain_dir)):
        if i.endswith('pt'):
            model_name = i

    interval = 30
    import shlex

    max_epochs = train_args.max_epoch
    batch_size = train_args.train_batch_size

    train_command = 'python3 -m yolov.train --project /root/data/output_temp --weights /root/data/input/{}/{} --epochs {} --batch-size {} --save_interval_epoch 1 --data /root/cocodata.yaml --hyp /root/hyp.scratch.yaml --cfg /root/yolov5s.yaml --workers 0'.format(pretrain_dir, model_name, max_epochs,batch_size)
    print(train_command)
    resume_command = "python3 -m yolov.train --resume data/output_temp/exp/weights/last.pt"

    yolo_train_args = shlex.split(train_command)
    yolo_resume_args = shlex.split(resume_command)

    # 训练开始前检查是否有weihts文件
    exp_list = os.listdir(temp_output_folder)
    flag = 0

    # 判断checkpoint是否存在 下面的无效代码均可省略
    checkpoint_path = os.apth.join(temp_output_folder, "exp", "weight", "last.pt")
    if os.path.exists(checkpoint_path):
        subprocess.Popen(yolo_resume_args)
    else:
        subprocess.Popen(yolo_train_args)

    if len(exp_list) != 0:
        # 定位到exp文件夹
        flag += 1
        exp_list = sorted(exp_list, key=lambda x: int(x[3:]) if x[3:].isdigit() else int(0))
        last_exp_folder = os.path.join(temp_output_folder, 'exp')

        # 如果exp存在路径weights
        # exp文件夹下的list
        exp_folder_list = os.listdir(last_exp_folder)
        weights_folder = os.path.join(last_exp_folder, "weights")

        # weights文件夹下的list
        if "weights" in exp_folder_list:
            flag += 1
            weights_list = os.listdir(weights_folder)

            if "last.pt" in weights_list:
                flag += 1
                # subprocess.Popen(yolo_resume_args)
                # print("Resume training!")
    flag = 2
    if flag != 3:
        subprocess.Popen(yolo_train_args)

    time.sleep(10)
    exp_list = os.listdir(temp_output_folder)
    # 对exp数据进行排序  每次选择最新生成的exp文件  ! sorted 中运用 lambda
    exp_list = sorted(exp_list, key = lambda x: int(x[3:]) if x[3:].isdigit() else int(0))

    last_exp_folder = os.path.join(temp_output_folder, 'exp')
    weights_folder = os.path.join(last_exp_folder, "weights")

    while True:
        time.sleep(interval)
        # 1. 遍历两个文件夹中的文件
        weights_list = os.listdir(weights_folder)
        output_model_list = os.listdir(output_model_folder)
        # 2. 比较两个文件夹中不同的文件，并复制到另一个文件夹中
        for weight_pt in weights_list:
            if weight_pt not in output_model_folder:
                shutil.copy(os.path.join(weights_folder, weight_pt), output_model_folder)

        # json部分开发
        # 不会的地方及时查找GPT，减少前期摸索时间，这个过程是最浪费时间的,需求一定要具体
        # 思路 √   data-> [datalist] 一张表 -> [list] ->  {"chartData" : list}
        # 思考 动态查看result.csv 是否有变化
        # 思路 直接封装进原本的程序中就行， 这个函数也会随着时间不断地复用

        # 实践2 完成对result.csv文件的处理
        df = pd.read_csv(os.path.join(last_exp_folder, "results.csv")).iloc[:, :8]
        # 获取行
        rows= len(df)
        # 获取列
        columns = df.shape[1]

        # 获取标题
        columns_names = df.columns.tolist()
        columns_names_list = [s.replace(' ', '') for s in columns_names]

        # 总的图表
        json_list = []
        # 一列就是一张表
        if "results.csv" in os.listdir(last_exp_folder):
            for column in range(1, columns):
                # 获取某一列的数据，也就是y0的数据
                column_data = df.iloc[:, column].tolist()
                column_data = np.array(column_data)

                # 创建一个新字典，表示这一个图表的信息
                chart_dict = {}
                # 开始对字典赋值
                chart_dict["title"] = columns_names_list[column] + " title"
                chart_dict["xAxis"] = {
                    "name": ["epoch"],
                    "max": rows
                }
                chart_dict["yAxis"] = {
                    "name": [columns_names_list[column]],
                    "max": float(column_data.max())
                }
                chart_dict["legend"] = "",

                # 专门存放data部分
                list_data = []
                for i in range(rows):
                    x0_data = str(i)
                    y0_data = str(column_data[i])
                    dict_data = {
                        "x0": x0_data,
                        "y0": y0_data
                    }
                    list_data.append(dict_data)

                chart_dict["data"] = list_data
                chart_dict["echartType"] = "line"
                chart_dict["subTitle"] = columns_names_list[column] + " subTitle"
                chart_dict["chartTitle"] = columns_names_list[column]
                chart_dict["classify"] = column
                json_list.append(chart_dict)

            json_data = {"chartData": json_list}

            # 创建存储结果的文件夹 /root/data/output_temp  /root/data/output/report
            with open(os.path.join(temp_output_folder, "detection_train.json"), "w") as file:
                json.dump(json_data, file, indent=4)
            with open(os.path.join(output_report_folder, "detection_train.json"), "w") as file:
                json.dump(json_data, file, indent=4)

def main(train_args):
    # 1. 对参数进行解析
    # 输入文件夹
    # /root/data/input/image
    image_folder = os.path.join("data", "input" ,train_args.input.split(",")[0])
    # /root/data/input/pretrain
    # pretrain_folder = os.path.join("root", "data", "input", train_args.input.split(".")[1])
    train_val_test_rate = train_args.train_val_test_rate

    # 2. 划分数据集
    images_folder = os.path.join(image_folder, "images")
    labels_folder =  os.path.join(image_folder, "annotations")
    string = train_val_test_rate
    split_string = string.split(":")
    int_list = list(map(int, split_string))
    train_set, val_set, test_set = int_list
    train_ratio, val_ratio, test_ratio = (train_set/10, val_set/10, test_set/10)
    # 创建划分数据集的文件夹
    train_folder = os.path.join(image_folder,'train')
    val_folder = os.path.join(image_folder,'val')
    test_folder = os.path.join(image_folder, 'test')
    os.makedirs(train_folder, exist_ok = True)
    os.makedirs(val_folder, exist_ok = True)
    os.makedirs(test_folder, exist_ok=True)

    # 遍历图片数据集
    image_files = os.listdir(images_folder)
    label_files = os.listdir(labels_folder)

    # 确保图片和标签的顺序一致
    image_files.sort()
    label_files.sort()

    # 随机打乱数据
    combined_data = list(zip(image_files, label_files))
    random.shuffle(combined_data)
    image_files, label_files = zip(*combined_data)

    # 计算每个数据集所需的数量
    num_images = len(image_files)
    num_train = int(train_ratio * num_images)
    num_val = int(val_ratio * num_images)
    num_test = int(test_ratio * num_images)

    # 划分并复制数据集到目标文件夹
    os.makedirs(os.path.join(train_folder, "images"), exist_ok=True)
    os.makedirs(os.path.join(train_folder, "annotations"), exist_ok=True)
    for i in range(num_train):
        shutil.copy2(os.path.join(images_folder, image_files[i]), os.path.join(train_folder, "images"))
        shutil.copy2(os.path.join(labels_folder, label_files[i]), os.path.join(train_folder, "annotations"))

    os.makedirs(os.path.join(val_folder, "images"), exist_ok=True)
    os.makedirs(os.path.join(val_folder, "annotations"), exist_ok=True)
    for i in range(num_train, num_train+num_val):
        shutil.copy2(os.path.join(images_folder, image_files[i]), os.path.join(val_folder, "images"))
        shutil.copy2(os.path.join(labels_folder, label_files[i]), os.path.join(val_folder, "annotations"))

    os.makedirs(os.path.join(test_folder, "images"), exist_ok=True)
    os.makedirs(os.path.join(test_folder, "annotations"), exist_ok=True)
    for i in range(num_train+num_val, num_images):
        shutil.copy2(os.path.join(images_folder, image_files[i]), os.path.join(test_folder, "images"))
        shutil.copy2(os.path.join(labels_folder, label_files[i]), os.path.join(test_folder, "annotations"))

    # 3. 转换为COCO数据集
    cocodata_foloder = os.path.join("data", "cocodata")
    os.makedirs(cocodata_foloder, exist_ok= True)
    coco_images = os.path.join(cocodata_foloder, "images")
    coco_labels = os.path.join(cocodata_foloder, "labels")
    os.makedirs(coco_images, exist_ok=True)
    os.makedirs(coco_labels, exist_ok=True)
    set_list = ['val', 'test', 'train']
    for set in set_list:
        os.makedirs(os.path.join(coco_labels, set), exist_ok = True)
        os.makedirs(os.path.join(coco_images, set), exist_ok = True)
    os.system("python3 -m yolov.conver2coco --input_dir /root/data/input/image/train --output_dir /root/data/cocodata --tag train")
    os.system("python3 -m yolov.conver2coco --input_dir /root/data/input/image/val --output_dir /root/data/cocodata --tag val")

    prepare_output()

    pass

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', type=str, default='image,model', help="输入的数据集文件夹")
    parser.add_argument('--output', type=str, default='report,model', help="输出的数据集文件夹")
    # 算子外部输入的参数
    parser.add_argument('--max_epoch', type=int, default=50, help="训练代数")
    parser.add_argument('--train_batch_size', type=int, default=16, help="训练批大小")
    parser.add_argument('--save_interval_epoch', type=int, default=1, help="checkpoint保存间隔代数")
    parser.add_argument('--train_val_test_rate', type=str, default='8:2:0', help="训练集:验证集:测试集")
    train_args = parser.parse_args()
    os.system("rm -rf core*")
    main(train_args)
```
